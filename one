Complete Documentation for Databricks Cluster Configuration, File Upload, and Job Configuration

Preparing the Environment:

Ensure access to Databricks and the Azure Portal.
Verify availability of the Log Analytics Workspace in Azure.
Confirm proxy and network settings are in place.
Modify Cluster Details and Set Up Advanced Options: To integrate Databricks with Azure Log Analytics and configure the environment correctly, follow these steps:

Modify Cluster Details:

Create a New Cluster in Databricks: Navigate to Clusters and click on Create Cluster.
Cluster Name: Provide a unique name for the cluster.
Databricks Runtime Version: Select the appropriate runtime version.
Node Type: Choose the appropriate node types for the workload.
Set Cluster ID:

Under Advanced Options, specify the Cluster ID dynamically or manually, depending on the specific cluster instance.
Advanced Settings – Modifying the .sh File: To include proxy settings and integrate with Azure Log Analytics, modify the .sh file as follows:

Steps to Modify the .sh File:

Prepare the .sh File:
Initial Setup: Open the .sh file to configure the initialization commands.
Modify Cluster Details: Add configurations for Log Analytics workspace:
Include the workspace ID and primary key.
Configure Proxy Settings: If a proxy is required, add the following:
bash
Copy code
export https_proxy="http://<proxy_host>:<proxy_port>"
export http_proxy="http://<proxy_host>:<proxy_port>"
Upload the .sh File to Databricks:

Go to Clusters in Databricks.
Select the cluster and open Advanced Options.
Under Init Scripts, upload the .sh file that includes proxy and Log Analytics configurations.
Note: While modifying the .sh file, add the other necessary configurations (like the workspace ID and any additional modifications) before uploading it in the Advanced Settings in the cluster.
Uploading Files (JAR, .sh, and spark-layout.json) into Volumes: The next step involves uploading the required files into the Databricks Volumes section so they are available for cluster initialization and execution.

Upload Files to Volumes:

Navigate to Data > Volumes in the Databricks workspace.
Upload necessary files like JAR files, .sh files, and configuration files to the cluster's volume. These files are essential for the job’s functionality and integration with Azure Log Analytics.
Example of files uploaded:

log4j-layout-template-json-2.17.2.jar
spark-monitoring.sh
spark-monitoring-1.0.0.jar
spark-monitoring-job-1.0.0.jar
spark-layout.json (this needs to be uploaded into the Volumes section as well)
Verify File Uploads:

Once uploaded, verify that the files are listed in the Volumes section in the Databricks workspace.
Building the JAR Using Maven:

Build the JAR File:

Use Maven to build the JAR that Databricks will use for job execution.
Example Maven command to build the JAR:
bash
Copy code
mvn clean install
Ensure that the pom.xml file includes all necessary dependencies and plugins for building the application.
Upload the Built JAR to Databricks:

Once the JAR is built, navigate to Databricks Libraries.
Click on Upload and select the generated JAR file.
This JAR will be available for the cluster to use when running the job.
Configuring Job Settings (with Advanced Settings): Once the files (including the .sh script, JAR files, and any other configurations) are uploaded, configure the job in Databricks. The advanced settings for adding environmental variables and spark configurations need to be done at this stage.

Configure Databricks Job:

Navigate to Jobs in Databricks and click on Create Job.
Provide a Job Name and configure its settings.
Select the cluster where the job will run.
Define the task for the job, which will involve running the uploaded JAR or Python script.
In the Advanced Options, configure the Init Scripts to include the uploaded .sh file, ensuring that proxy settings and other environment variables are configured before the job runs.
Attach Libraries to the Job:

Under the Libraries section in the Job configuration, ensure that the necessary JAR files (spark-monitoring-1.0.0.jar, spark-monitoring-job-1.0.0.jar) are attached. These JARs are crucial for the job’s execution and are used for monitoring purposes.
Job Execution:

Configure job parameters (if any) and ensure the job is set to trigger either on a schedule or manually, depending on the requirements.
Once the job is configured, run the job and monitor its execution via the Databricks Jobs UI.
Modifying the .sh File for Log Analytics Integration: To ensure proper integration with Log Analytics:

Modify the .sh File:

In the .sh file, specify the Log Analytics workspace ID and primary key.
Example configuration:
bash
Copy code
WORKSPACE_ID=<Your_Workspace_ID>
PRIMARY_KEY=<Your_Primary_Key>
Ensure the log data is pushed to the Log Analytics workspace:
bash
Copy code
curl -X POST https://<workspace_id>.ods.opinsights.azure.com/api/logs?api-version=2016-04-01
Upload the Modified .sh File:

After modifying the .sh file, upload it to the Init Scripts section in Databricks.
Ensure that the cluster can connect securely to the Log Analytics workspace without any network issues.
Test and Validate the Setup:

Run the Job: Submit a job using the configured settings and ensure that logs are generated.
Verify Logs in Log Analytics: Go to Azure Portal > Log Analytics Workspace > Logs and run queries to check that the Databricks logs are successfully forwarded to Log Analytics.
Check Network Connectivity: Ensure that the cluster is properly communicating with the Log Analytics workspace via Private Link or other secure network methods.
Final Cluster Settings:

Attach Init Scripts to the Cluster: Attach the init scripts to the cluster and upload JAR files and other necessary configuration files.
Start the Cluster: After configuring the init scripts and uploading the files, start the cluster. The cluster will automatically run the .sh file during initialization, setting up the necessary environment for job execution.
Conclusion: By following these detailed steps, the Databricks environment is configured with the necessary files, proxies, Log Analytics integration, and job configurations. This setup guarantees that the Databricks jobs run smoothly, monitor performance, and push logs to Azure Log Analytics for monitoring and troubleshooting.
