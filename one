from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Delta Table Creation").getOrCreate()

# Creating a database in the Hive metastore
spark.sql("CREATE DATABASE IF NOT EXISTS SampleDB")
spark.sql("USE SampleDB")

# Delta table in the Hive metastore within the created database
spark.sql("CREATE TABLE HiveDeltaTable (id INT, name STRING) USING DELTA")
spark.sql("INSERT INTO HiveDeltaTable VALUES (1, 'Alice'), (2, 'Bob')")

# Creating and writing to a Delta table in DBFS
data = [(3, 'Charlie'), (4, 'David')]
df = spark.createDataFrame(data, ["id", "name"])
df.write.format("delta").mode("overwrite").save("/mnt/delta/DBFSDeltaTable")




from pyspark.sql import SparkSession
from pyspark.sql.functions import expr
from delta.tables import DeltaTable

spark = SparkSession.builder.appName("ACID Transactions in Delta Lake").getOrCreate()

delta_path = "/mnt/delta/ACIDTransactionsDeltaTable"
spark.sql(f"CREATE TABLE IF NOT EXISTS transactions (transaction_id INT, amount DECIMAL(10,2), description STRING) USING DELTA LOCATION '{delta_path}'")
spark.sql("INSERT INTO transactions VALUES (1, 100.00, 'Initial deposit'), (2, 200.00, 'Initial deposit')")

delta_table = DeltaTable.forPath(spark, delta_path)
delta_table.toDF().show()

delta_table.update(condition = expr("transaction_id = 1"), set = {"amount": expr("amount + 50.00")})
delta_table.delete(condition = expr("transaction_id = 2"))

upsert_data = spark.createDataFrame([(3, 300.00, 'New deposit')], ["transaction_id", "amount", "description"])
delta_table.alias("t").merge(
    upsert_data.alias("u"), 
    "t.transaction_id = u.transaction_id"
).whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()

delta_table.toDF().show()
